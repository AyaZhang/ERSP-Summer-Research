{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy.optimize\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "import parseData\n",
    "import analysis\n",
    "\n",
    "pathProducts = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\meta_shoes_unique+fifteen_review+price.txt\"\n",
    "pathReviews = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\reviews_shoes_unique+fifteen_review+price.txt\"\n",
    "pathLabels = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\labels.txt\"\n",
    "\n",
    "shoes = parseData.parse(pathProducts)\n",
    "reviews = parseData.parse(pathReviews)\n",
    "labels = parseData.loadLabels(pathLabels)\n",
    "\n",
    "for key, value in labels.items():\n",
    "  if value == 0:\n",
    "    del labels[key]\n",
    "\n",
    "print len(labels)\n",
    "\n",
    "sample_shoes = dict()\n",
    "for i in shoes:\n",
    "  if i['asin'] in labels.keys():\n",
    "    sample_shoes[i['asin']] = i\n",
    "\n",
    "sample_reviews = list()\n",
    "for i in reviews:\n",
    "  if i['asin'] in labels.keys():\n",
    "    sample_reviews.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Athletic & Outdoor', 'Outdoor', 'Loafers', 'Athletic', 'Men', 'Boots', 'Clogs & Mules', 'Fashion Sneakers', 'Women', 'Pumps', 'Oxfords', 'Flats', 'Sneakers', 'Sandals', 'Kids & Baby', 'Loafers & Slip-Ons', 'Slippers', 'Mules & Clogs'])\n"
     ]
    }
   ],
   "source": [
    "# extract sub-categories\n",
    "\n",
    "subcategories = set()\n",
    "for key,value in sample_shoes.iteritems():\n",
    "    for i in value['categories']:\n",
    "      for j in range(0, len(i)):\n",
    "        if i[j]== 'Shoes':\n",
    "          if j+1 < len(i):\n",
    "            subcategories.add(i[j+1])\n",
    "            break\n",
    "\n",
    "print subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into training set, validation set, and test set\n",
    "\n",
    "import random\n",
    "\n",
    "training_set = random.sample(sample_shoes.items(), 1179)\n",
    "\n",
    "for i in training_set:\n",
    "  del sample_shoes[i[0]]\n",
    "\n",
    "validation_set = random.sample(sample_shoes.items(), 200)\n",
    "\n",
    "for i in validation_set:\n",
    "  del sample_shoes[i[0]]\n",
    "\n",
    "test_set = random.sample(sample_shoes.items(), 200)\n",
    "\n",
    "# print training_set[0][1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# feature: price\n",
    "\n",
    "def feature(key):\n",
    "  feat = [1]\n",
    "  feat.append(sample_shoes[key]['price'])  # price feature\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# feature: price and popularity\n",
    "\n",
    "def feature(key):\n",
    "  feat = [1]\n",
    "  feat.append(sample_shoes[key]['price'])  # price feature\n",
    "  count = 0\n",
    "  for i in sample_reviews:\n",
    "    if i['asin'] == key:\n",
    "      count += 1\n",
    "  feat.append(count) # popularity feature\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# feature: keywords\n",
    "\n",
    "reviewList = parseData.tokenize(sample_reviews)\n",
    "words = analysis.commonWords(reviewList, 500)\n",
    "\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(key):\n",
    "  feat = [0] * len(words)\n",
    "  for i in range(0, len(sample_reviews)):\n",
    "    if sample_reviews[i]['asin'] == key[0]:\n",
    "      review = reviewList[i]\n",
    "  for w in review:\n",
    "    if w in words:\n",
    "      feat[wordID[w]] += 1\n",
    "  feat.append(1)  #offset\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.95\n",
      "364.95\n"
     ]
    }
   ],
   "source": [
    "# Regularize price feature\n",
    "\n",
    "min_price = 999999\n",
    "max_price = 0\n",
    "\n",
    "for i,j in sample_shoes.items():\n",
    "  if j['price'] > max_price:\n",
    "    max_price = j['price']\n",
    "  elif j['price'] < min_price:\n",
    "    min_price = j['price']\n",
    "    \n",
    "print min_price\n",
    "print max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "# Regularize popularity feature\n",
    "\n",
    "min_reviews = 999999\n",
    "max_reviews = 0\n",
    "\n",
    "for i in sample_shoes:\n",
    "  count = 0\n",
    "  for j in sample_reviews:\n",
    "    if i == j['asin']:\n",
    "      count += 1\n",
    "  if count > max_reviews:\n",
    "    max_reviews = count\n",
    "  elif count < min_reviews:\n",
    "    min_reviews = count\n",
    "\n",
    "print min_reviews\n",
    "print max_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common words dictionary\n",
    "\n",
    "reviewList = parseData.tokenize(sample_reviews)\n",
    "words = analysis.commonWords(reviewList, 800)\n",
    "\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n",
      "169991\n"
     ]
    }
   ],
   "source": [
    "# Regularize word counts\n",
    "\n",
    "word_count = [0] * len(wordID)\n",
    "for r in reviewList:\n",
    "  for w in r:\n",
    "    if w in words:\n",
    "      word_count[wordID[w]] += 1\n",
    "\n",
    "min_occurrence = min(word_count)\n",
    "max_occurrence = max(word_count)\n",
    "\n",
    "print min_occurrence\n",
    "print max_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature: price, popularity, keywords and subcategory\n",
    "\n",
    "def feature(key):\n",
    "  feat = [0] * len(words)\n",
    "  for i in range(0, len(sample_reviews)):\n",
    "    if sample_reviews[i]['asin'] == key[0]:\n",
    "      review = reviewList[i]\n",
    "      for w in review:\n",
    "        if w in words:\n",
    "          feat[wordID[w]] += 1    # keyword feature\n",
    "  for i in range(0, len(wordID)):\n",
    "    feat[i] = 1.0*feat[i]/word_count[i]\n",
    "  feat.append(key[1]['price']/max_price)  # price feature\n",
    "  count = 0\n",
    "  for i in sample_reviews:\n",
    "    if i['asin'] == key[0]:\n",
    "      count += 1\n",
    "  feat.append(count/max_reviews)   # popularity feature\n",
    "  cat = 0\n",
    "  for i in key[1]['categories']:\n",
    "    for j in range(0, len(i)):\n",
    "      if i[j] == 'Shoes' and j+1 < len(i):\n",
    "        cat = i[j+1]\n",
    "        break\n",
    "  for i in subcategories:\n",
    "    if i != cat:\n",
    "      feat.append(0)\n",
    "    else:\n",
    "      feat.append(1)\n",
    "  feat.append(1)  #offset\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at theta and residuals on training set\n",
    "\n",
    "#wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y = [labels[i[0]] for i in training_set]\n",
    "X = [feature(i) for i in training_set]\n",
    "\n",
    "# theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "# print theta\n",
    "# print residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of suquared error:  493.574450316\n",
      "Coefficient of determination R^2:  0.787190577261\n",
      "Coefficient of determination R^2:  -0.213823674416\n",
      "Sum of suquared error:  260.488916363\n",
      "Coefficient of determination R^2:  0.673763814281\n",
      "Coefficient of determination R^2:  0.359392259057\n",
      "Sum of suquared error:  212.292093711\n",
      "Coefficient of determination R^2:  0.534045320807\n",
      "Coefficient of determination R^2:  0.477920364246\n",
      "Sum of suquared error:  232.940765266\n",
      "Coefficient of determination R^2:  0.438934764492\n",
      "Coefficient of determination R^2:  0.427140089129\n",
      "Sum of suquared error:  240.092755777\n",
      "Coefficient of determination R^2:  0.405665331884\n",
      "Coefficient of determination R^2:  0.409551546211\n",
      "Sum of suquared error:  241.46085715\n",
      "Coefficient of determination R^2:  0.392009557499\n",
      "Coefficient of determination R^2:  0.40618704095\n",
      "Sum of suquared error:  272.813425137\n",
      "Coefficient of determination R^2:  0.315162981478\n",
      "Coefficient of determination R^2:  0.329083193189\n",
      "Sum of suquared error:  362.533876005\n",
      "Coefficient of determination R^2:  0.107452626219\n",
      "Coefficient of determination R^2:  0.108438045788\n",
      "Sum of suquared error:  401.90940627\n",
      "Coefficient of determination R^2:  0.0140572867181\n",
      "Coefficient of determination R^2:  0.0116037165449\n",
      "Sum of suquared error:  407.202928154\n",
      "Coefficient of determination R^2:  0.00144982542664\n",
      "Coefficient of determination R^2:  -0.00141438473736\n"
     ]
    }
   ],
   "source": [
    "# perform ridge regression\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "max_score = 0\n",
    "lbda = 0.0001\n",
    "\n",
    "for a in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]:\n",
    "  clf = Ridge(alpha=a)\n",
    "  clf.fit(X, y) \n",
    "\n",
    "  y_validation = [labels[i[0]] for i in validation_set]\n",
    "  X_validation = [feature(i) for i in validation_set]\n",
    "\n",
    "  p = clf.predict(X_validation)\n",
    "  print \"Sum of suquared error: \", sum((b-c)**2 for (b,c) in zip(p, y_validation))\n",
    "  print \"Coefficient of determination R^2: \", clf.score(X, y)\n",
    "  score = clf.score(X_validation, y_validation)\n",
    "  print \"Coefficient of determination R^2: \", score\n",
    "\n",
    "  if score > max_score:\n",
    "    max_score = score\n",
    "    lbda = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use comfortably care kept expect brand flat product longer pleased pairs help slipping went told easy find item needed held inserts using comes shape mine their ground toe easily nothing ones poor higher cheaper seller solid house sent insoles trouble given money work provide flexible period type stores average lasted clarks saucony things rather sandal broken sandals stay hoping waterproof across daily decent based red break blue clean match inches husband water keeps pay arch slip others insole green likes plantar spend arches broke local weeks customer office flats rubber stitching finding keen job slipper flops plastic flip hiking velcro crocs\n",
      "fun sexy white upper cute compliments beautiful cool skirts dress picture fur adorable awesome absolutely plan hit smell footbed dont gift clogs dance leg twice gotten christmas jeans cozy saw im zipper legs height forward lots birkenstock gorgeous calves fantastic please described show taking fabric wedding loved five skinny exchange oh anyway lining issue design construction amazing mind loves dansko she sneakers fell quick athletic purchasing looks super heal looked supportive excited warm pants today must free front unfortunately suede person giving version straps friends him balance star believe tad where air weather calf surprised top goes look part women\n"
     ]
    }
   ],
   "source": [
    "# Find out the most status/utility words\n",
    "\n",
    "clf = Ridge(alpha=lbda)\n",
    "clf.fit(X, y)\n",
    "\n",
    "utility = []\n",
    "index = 0\n",
    "for t in range(0, 800):\n",
    "  utility.append((clf.coef_[t], index))\n",
    "  index += 1\n",
    "\n",
    "status = []\n",
    "index = 0\n",
    "for t in range(0, 800):\n",
    "  status.append((clf.coef_[t],index))\n",
    "  index += 1\n",
    "\n",
    "utility.sort()\n",
    "utility_words = utility[-101:]\n",
    "\n",
    "status.sort()\n",
    "status_words = status[:100]\n",
    "\n",
    "wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "for i in utility_words:\n",
    "  if i[1] < len(wordID):\n",
    "    print wordID[i[1]],\n",
    "    #print clf.coef_[i[1]],\n",
    "\n",
    "print \n",
    "\n",
    "for i in status_words:\n",
    "  print wordID[i[1]],\n",
    "  #print clf.coef_[i[1]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.31182796  1.        ]\n",
      "[ 0.          0.87850467  1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "y = []\n",
    "for i in y_test:\n",
    "  if i > 3:\n",
    "    y.append(1)\n",
    "  else:\n",
    "    y.append(0)\n",
    "\n",
    "\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "score = []\n",
    "for i in p:\n",
    "  if i > 3:\n",
    "    score.append(1)\n",
    "  else:\n",
    "    score.append(0)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, score)\n",
    "\n",
    "print fpr\n",
    "print tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "colors = []\n",
    "for i in range(0, 200):\n",
    "  if y_test[i] > 3 and p[i] > 3:\n",
    "    colors.append('blue')\n",
    "  elif y_test[i] < 3 and p[i] < 3:\n",
    "    colors.append('red')\n",
    "  else:\n",
    "    colors.append('purple')\n",
    "\n",
    "plt.scatter(y_test, p, c=colors, alpha=0.5)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.title('Scatter plot of prediction result')\n",
    "#plt.grid(True)\n",
    "plt.text(5.1, 5.4, 'uility goods', fontsize=10, color='blue', alpha = 0.7) \n",
    "plt.text(5.1, 5.2, 'true positive', fontsize=10, color='blue', alpha = 0.7)\n",
    "plt.text(0.1, 0.3, 'status goods', fontsize=10, color='red', alpha = 0.7) \n",
    "plt.text(0.1, 0.1, 'false negative', fontsize=10, color='red', alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "62\n",
      "107\n",
      "88\n",
      "0.704545454545\n",
      "0.295454545455\n",
      "0.878504672897\n",
      "0.147727272727\n"
     ]
    }
   ],
   "source": [
    "# the histogram of the data\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "\n",
    "correct_utility_counts = 0\n",
    "correct_status_counts = 0\n",
    "total_utility = 0\n",
    "total_status = 0\n",
    "\n",
    "for i in range(0,200):\n",
    "  if y_test[i] > 3:\n",
    "    total_utility += 1\n",
    "    if p[i] > 3:\n",
    "      correct_utility_counts += 1\n",
    "  elif y_test[i] < 3:\n",
    "    total_status += 1\n",
    "    if p[i] < 3:\n",
    "      correct_status_counts += 1\n",
    "\n",
    "print correct_utility_counts\n",
    "print correct_status_counts\n",
    "print total_utility\n",
    "print total_status\n",
    "\n",
    "print 1.0 * correct_status_counts/total_status\n",
    "print 1.0 * (total_status-correct_status_counts)/total_status\n",
    "print 1.0 * correct_utility_counts/total_utility\n",
    "print 1.0 * (total_utility-correct_utility_counts)/total_status\n",
    "\n",
    "#n, bins, patches = plt.hist(x, 50, facecolor='g', alpha=0.7)\n",
    "\n",
    "#plt.xlabel('Labels')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title('Histogram of IQ')\n",
    "#plt.grid(True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
