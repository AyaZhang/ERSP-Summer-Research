{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy.optimize\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "import parseData\n",
    "import analysis\n",
    "\n",
    "pathProducts = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\meta_shoes_unique+fifteen_review+price.txt\"\n",
    "pathReviews = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\reviews_shoes_unique+fifteen_review+price.txt\"\n",
    "pathLabels = r\"C:\\Users\\Yijun\\Desktop\\Amazon\\labels.txt\"\n",
    "\n",
    "shoes = parseData.parse(pathProducts)\n",
    "reviews = parseData.parse(pathReviews)\n",
    "labels = parseData.loadLabels(pathLabels)\n",
    "\n",
    "for key, value in labels.items():\n",
    "  if value == 0:\n",
    "    del labels[key]\n",
    "\n",
    "print len(labels)\n",
    "\n",
    "sample_shoes = dict()\n",
    "for i in shoes:\n",
    "  if i['asin'] in labels.keys():\n",
    "    sample_shoes[i['asin']] = i\n",
    "\n",
    "sample_reviews = list()\n",
    "for i in reviews:\n",
    "  if i['asin'] in labels.keys():\n",
    "    sample_reviews.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Athletic & Outdoor', 'Outdoor', 'Loafers', 'Athletic', 'Men', 'Boots', 'Clogs & Mules', 'Fashion Sneakers', 'Women', 'Pumps', 'Oxfords', 'Flats', 'Sneakers', 'Sandals', 'Kids & Baby', 'Loafers & Slip-Ons', 'Slippers', 'Mules & Clogs'])\n"
     ]
    }
   ],
   "source": [
    "# extract sub-categories\n",
    "\n",
    "subcategories = set()\n",
    "for key,value in sample_shoes.iteritems():\n",
    "    for i in value['categories']:\n",
    "      for j in range(0, len(i)):\n",
    "        if i[j]== 'Shoes':\n",
    "          if j+1 < len(i):\n",
    "            subcategories.add(i[j+1])\n",
    "            break\n",
    "\n",
    "print subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into training set, validation set, and test set\n",
    "\n",
    "import random\n",
    "\n",
    "training_set = random.sample(sample_shoes.items(), 1179)\n",
    "\n",
    "for i in training_set:\n",
    "  del sample_shoes[i[0]]\n",
    "\n",
    "validation_set = random.sample(sample_shoes.items(), 200)\n",
    "\n",
    "for i in validation_set:\n",
    "  del sample_shoes[i[0]]\n",
    "\n",
    "test_set = random.sample(sample_shoes.items(), 200)\n",
    "\n",
    "# print training_set[0][1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# feature: price\n",
    "\n",
    "def feature(key):\n",
    "  feat = [1]\n",
    "  feat.append(sample_shoes[key]['price'])  # price feature\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# feature: price and popularity\n",
    "\n",
    "def feature(key):\n",
    "  feat = [1]\n",
    "  feat.append(sample_shoes[key]['price'])  # price feature\n",
    "  count = 0\n",
    "  for i in sample_reviews:\n",
    "    if i['asin'] == key:\n",
    "      count += 1\n",
    "  feat.append(count) # popularity feature\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# feature: keywords\n",
    "\n",
    "reviewList = parseData.tokenize(sample_reviews)\n",
    "words = analysis.commonWords(reviewList, 500)\n",
    "\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(key):\n",
    "  feat = [0] * len(words)\n",
    "  for i in range(0, len(sample_reviews)):\n",
    "    if sample_reviews[i]['asin'] == key[0]:\n",
    "      review = reviewList[i]\n",
    "  for w in review:\n",
    "    if w in words:\n",
    "      feat[wordID[w]] += 1\n",
    "  feat.append(1)  #offset\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.75\n",
      "324.95\n"
     ]
    }
   ],
   "source": [
    "# Regularize price feature\n",
    "\n",
    "min_price = 999999\n",
    "max_price = 0\n",
    "\n",
    "for i,j in sample_shoes.items():\n",
    "  if j['price'] > max_price:\n",
    "    max_price = j['price']\n",
    "  elif j['price'] < min_price:\n",
    "    min_price = j['price']\n",
    "    \n",
    "print min_price\n",
    "print max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1513\n"
     ]
    }
   ],
   "source": [
    "# Regularize popularity feature\n",
    "\n",
    "min_reviews = 999999\n",
    "max_reviews = 0\n",
    "\n",
    "for i in sample_shoes:\n",
    "  count = 0\n",
    "  for j in sample_reviews:\n",
    "    if i == j['asin']:\n",
    "      count += 1\n",
    "  if count > max_reviews:\n",
    "    max_reviews = count\n",
    "  elif count < min_reviews:\n",
    "    min_reviews = count\n",
    "\n",
    "print min_reviews\n",
    "print max_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common words dictionary\n",
    "\n",
    "reviewList = parseData.tokenize(sample_reviews)\n",
    "words = analysis.commonWords(reviewList, 800)\n",
    "\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n",
      "169991\n"
     ]
    }
   ],
   "source": [
    "# Regularize word counts\n",
    "\n",
    "word_count = [0] * len(wordID)\n",
    "for r in reviewList:\n",
    "  for w in r:\n",
    "    if w in words:\n",
    "      word_count[wordID[w]] += 1\n",
    "\n",
    "min_occurrence = min(word_count)\n",
    "max_occurrence = max(word_count)\n",
    "\n",
    "print min_occurrence\n",
    "print max_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature: price, popularity, keywords and subcategory\n",
    "\n",
    "def feature(key):\n",
    "  feat = [0] * len(words)\n",
    "  for i in range(0, len(sample_reviews)):\n",
    "    if sample_reviews[i]['asin'] == key[0]:\n",
    "      review = reviewList[i]\n",
    "      for w in review:\n",
    "        if w in words:\n",
    "          feat[wordID[w]] += 1    # keyword feature\n",
    "  for i in range(0, len(wordID)):\n",
    "    feat[i] = 1.0*feat[i]/word_count[i]\n",
    "  feat.append(key[1]['price']/max_price)  # price feature\n",
    "  count = 0\n",
    "  for i in sample_reviews:\n",
    "    if i['asin'] == key[0]:\n",
    "      count += 1\n",
    "  feat.append(count/max_reviews)   # popularity feature\n",
    "  cat = 0\n",
    "  for i in key[1]['categories']:\n",
    "    for j in range(0, len(i)):\n",
    "      if i[j] == 'Shoes' and j+1 < len(i):\n",
    "        cat = i[j+1]\n",
    "        break\n",
    "  for i in subcategories:\n",
    "    if i != cat:\n",
    "      feat.append(0)\n",
    "    else:\n",
    "      feat.append(1)\n",
    "  feat.append(1)  #offset\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at theta and residuals on training set\n",
    "\n",
    "#wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y = [labels[i[0]] for i in training_set]\n",
    "X = [feature(i) for i in training_set]\n",
    "\n",
    "# theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "# print theta\n",
    "# print residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of suquared error:  470.227183752\n",
      "Coefficient of determination R^2:  0.792618185898\n",
      "Coefficient of determination R^2:  -0.202780876714\n",
      "Sum of suquared error:  367.893320403\n",
      "Coefficient of determination R^2:  0.684910866792\n",
      "Coefficient of determination R^2:  0.0589760317112\n",
      "Sum of suquared error:  236.887221243\n",
      "Coefficient of determination R^2:  0.548038085199\n",
      "Coefficient of determination R^2:  0.394072845012\n",
      "Sum of suquared error:  232.445742944\n",
      "Coefficient of determination R^2:  0.447578849979\n",
      "Coefficient of determination R^2:  0.405433577328\n",
      "Sum of suquared error:  246.723926296\n",
      "Coefficient of determination R^2:  0.413854185482\n",
      "Coefficient of determination R^2:  0.368911814054\n",
      "Sum of suquared error:  250.408922085\n",
      "Coefficient of determination R^2:  0.401789327708\n",
      "Coefficient of determination R^2:  0.359486067054\n",
      "Sum of suquared error:  270.122329987\n",
      "Coefficient of determination R^2:  0.32513489967\n",
      "Coefficient of determination R^2:  0.309061695903\n",
      "Sum of suquared error:  348.622355922\n",
      "Coefficient of determination R^2:  0.109883298311\n",
      "Coefficient of determination R^2:  0.108268689289\n",
      "Sum of suquared error:  385.906147272\n",
      "Coefficient of determination R^2:  0.0143279574338\n",
      "Coefficient of determination R^2:  0.0129015289116\n",
      "Sum of suquared error:  390.966608979\n",
      "Coefficient of determination R^2:  0.00147715256779\n",
      "Coefficient of determination R^2:  -4.24836397059e-05\n"
     ]
    }
   ],
   "source": [
    "# perform ridge regression\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "max_score = 0\n",
    "lbda = 0.0001\n",
    "\n",
    "for a in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]:\n",
    "  clf = Ridge(alpha=a)\n",
    "  clf.fit(X, y) \n",
    "\n",
    "  y_validation = [labels[i[0]] for i in validation_set]\n",
    "  X_validation = [feature(i) for i in validation_set]\n",
    "\n",
    "  p = clf.predict(X_validation)\n",
    "  print \"Sum of suquared error: \", sum((b-c)**2 for (b,c) in zip(p, y_validation))\n",
    "  print \"Coefficient of determination R^2: \", clf.score(X, y)\n",
    "  score = clf.score(X_validation, y_validation)\n",
    "  print \"Coefficient of determination R^2: \", score\n",
    "\n",
    "  if score > max_score:\n",
    "    max_score = score\n",
    "    lbda = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etc 0.703791040928 recommended 0.706773990434 others 0.710903288905 summer 0.718522023086 rub 0.731500538475 third 0.733347376493 brands 0.739386333685 stretch 0.754331081484 several 0.757248150861 decent 0.758042220024 sole 0.760499593923 expensive 0.76149846112 seem 0.769677406724 owned 0.776638828947 months 0.784657792389 sore 0.785946414263 across 0.795120381223 arch 0.799483547767 gel 0.800186793444 break 0.800396481118 toe 0.801171431746 his 0.814021431701 arches 0.851504861441 difference 0.856638966939 hold 0.857271362912 value 0.862067565341 gone 0.871140973538 pairs 0.873642758734 lasted 0.877989823736 wet 0.883730435876 likes 0.884877665968 laces 0.887779784159 holding 0.89319940623 waterproof 0.893999683866 become 0.896973136704 work 0.898390522545 period 0.89871070511 pay 0.899482114937 durable 0.902907798177 place 0.904603406977 trip 0.921720517047 sides 0.936333980857 replacement 0.937107485971 help 0.938821721697 slip 0.95203015383 traction 0.958493008645 product 0.973791020045 brooks 0.974765492729 type 0.975871501401 strong 0.976621580577 holes 0.992367953119 provide 0.994507873709 walks 0.996743086662 fitting 1.00041549071 customer 1.00741722166 shape 1.01235275104 given 1.02623541881 offer 1.03046621034 replace 1.04340645391 rubber 1.04718109443 weeks 1.08446629142 he 1.09663547186 gym 1.10806603482 solid 1.1254194239 local 1.14795759856 keen 1.14830692912 grip 1.15914671221 saucony 1.17813033229 use 1.1786025005 slipping 1.19023595092 dog 1.19058356709 floors 1.1994975494 water 1.19951552801 insert 1.21139569413 stitching 1.22089383969 husband 1.23560778902 spend 1.23581297324 sandal 1.24309623437 sandals 1.27048602443 insole 1.27109102683 using 1.31241127047 clean 1.31460544861 finding 1.33301544205 daily 1.33561887394 original 1.34177503236 item 1.3708077222 office 1.39250124395 slipper 1.42019224993 insoles 1.53598141501 flop 1.54362690638 inserts 1.65682412273 works 1.70474224445 job 1.70489227103 flats 1.80981700665 garden 1.83977396529 plastic 2.81179594654 crocs 3.06833985428 hiking 3.36679680142 velcro 3.44177658048 flops 4.18276012188 flip 4.22508771106\n",
      "sexy -3.58868212403 fun -3.31067141276 adorable -2.84962650969 wedding -2.60162647026 beautiful -2.54744961742 clogs -2.50761474019 compliments -2.1815072789 cute -2.16463589731 christmas -2.1232197098 dansko -2.05093241047 dance -1.98658160946 dress -1.91928587762 gorgeous -1.91615064839 girl -1.90669085906 skirts -1.86207283758 zipper -1.85478900439 height -1.84084453446 gift -1.69226374875 leg -1.61765921997 fur -1.57947231359 skinny -1.46662432675 she -1.43469003769 saw -1.42738948599 hit -1.42689521998 absolutely -1.42606652824 picture -1.40451436385 excited -1.36357813169 night -1.3413670939 tall -1.30911874478 calves -1.28076048013 loved -1.28059642234 awesome -1.24797499436 fell -1.23254530324 looked -1.22642237282 person -1.22248877036 jeans -1.12118716007 suede -1.11291182757 lots -1.09986780494 wait -1.09117236587 oh -1.08922505112 amazing -1.08253209532 legs -1.06760082276 cool -1.02920071271 high -0.987192172571 dont -0.969198867774 super -0.956200744858 her -0.93529942137 daughter -0.934145042097 anyway -0.933481284148 purchasing -0.929591251345 real -0.928093760406 fall -0.900463785411 forward -0.899622544099 calf -0.896450921463 fantastic -0.887324688596 please -0.869315319788 gotten -0.868780729639 putting -0.859844236848 stylish -0.856531058207 look -0.851172615722 supportive -0.826006620908 someone -0.822973799594 loves -0.807410773084 under -0.799024987356 exchange -0.79511937373 friends -0.776541223996 pink -0.767351184603 grey -0.76265293984 heels -0.75536560635 chance -0.740435076683 white -0.730120974003 straps -0.723066967474 knee -0.690865752615 ankles -0.687427555646 love -0.677081929712 true -0.67393391601 tad -0.673882607965 top -0.662302412506 cozy -0.655644147709 everyone -0.652804302965 read -0.6253243318 im -0.617697118217 thank -0.611931920955 everything -0.600148019082 footbed -0.595846191755 got -0.592708307086 knees -0.589774173949 worried -0.589684324676 pretty -0.581575477362 surprised -0.558397894591 complaint -0.558167359538 mind -0.557252287574 down -0.554027608818 fabric -0.541497339343 ice -0.538638640607 shaft -0.535169061596 thinking -0.534684973073 heel -0.525102354375 today -0.520875533525 told -0.5202701721\n"
     ]
    }
   ],
   "source": [
    "# Find out the most status/utility words\n",
    "\n",
    "clf = Ridge(alpha=lbda)\n",
    "clf.fit(X, y)\n",
    "\n",
    "utility = []\n",
    "index = 0\n",
    "for t in range(0, 800):\n",
    "  utility.append((clf.coef_[t], index))\n",
    "  index += 1\n",
    "\n",
    "status = []\n",
    "index = 0\n",
    "for t in range(0, 800):\n",
    "  status.append((clf.coef_[t],index))\n",
    "  index += 1\n",
    "\n",
    "utility.sort()\n",
    "utility_words = utility[-101:]\n",
    "\n",
    "status.sort()\n",
    "status_words = status[:100]\n",
    "\n",
    "wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "for i in utility_words:\n",
    "  if i[1] < len(wordID):\n",
    "    print wordID[i[1]],\n",
    "    print clf.coef_[i[1]],\n",
    "\n",
    "print \n",
    "\n",
    "for i in status_words:\n",
    "  print wordID[i[1]],\n",
    "  print clf.coef_[i[1]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1. ]\n",
      "[ 0.          0.89795918  1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "y = []\n",
    "for i in y_test:\n",
    "  if i > 3:\n",
    "    y.append(1)\n",
    "  else:\n",
    "    y.append(0)\n",
    "\n",
    "\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "score = []\n",
    "for i in p:\n",
    "  if i > 3:\n",
    "    score.append(1)\n",
    "  else:\n",
    "    score.append(0)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, score)\n",
    "\n",
    "print fpr\n",
    "print tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#wordID = dict((y,x) for x,y in wordID.iteritems())\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "colors = []\n",
    "for i in range(0, 200):\n",
    "  if y_test[i] > 3 and p[i] > 3:\n",
    "    colors.append('blue')\n",
    "  elif y_test[i] < 3 and p[i] < 3:\n",
    "    colors.append('red')\n",
    "  else:\n",
    "    colors.append('purple')\n",
    "\n",
    "plt.scatter(y_test, p, c=colors, alpha=0.5)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.title('Scatter plot of prediction result')\n",
    "#plt.grid(True)\n",
    "plt.text(5.1, 5.4, 'uility goods', fontsize=10, color='blue', alpha = 0.7) \n",
    "plt.text(5.1, 5.2, 'true positive', fontsize=10, color='blue', alpha = 0.7)\n",
    "plt.text(0.1, 0.3, 'status goods', fontsize=10, color='red', alpha = 0.7) \n",
    "plt.text(0.1, 0.1, 'false negative', fontsize=10, color='red', alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "51\n",
      "0\n",
      "98\n",
      "94\n",
      "8\n",
      "0.542553191489\n",
      "0.457446808511\n",
      "1.0\n",
      "0.897959183673\n",
      "0.102040816327\n",
      "1.0\n",
      "0.723958333333\n"
     ]
    }
   ],
   "source": [
    "# the histogram of the data\n",
    "\n",
    "y_test = numpy.array([labels[i[0]] for i in test_set])\n",
    "X_test = [feature(i) for i in test_set]\n",
    "p = clf.predict(X_test)\n",
    "p = numpy.array(p)\n",
    "\n",
    "correct_utility_counts = 0\n",
    "correct_status_counts = 0\n",
    "correct_middle_counts = 0\n",
    "total_utility = 0\n",
    "total_status = 0\n",
    "total_middle = 0\n",
    "\n",
    "for i in range(0,200):\n",
    "  if y_test[i] > 3:\n",
    "    total_utility += 1\n",
    "    if p[i] > 3:\n",
    "      correct_utility_counts += 1\n",
    "  elif y_test[i] < 3:\n",
    "    total_status += 1\n",
    "    if p[i] < 3:\n",
    "      correct_status_counts += 1\n",
    "  elif y_test[i] == 3:\n",
    "    total_middle += 1\n",
    "    if p[i] == 3:\n",
    "      correct_middle_counts += 1\n",
    "\n",
    "print correct_utility_counts\n",
    "print correct_status_counts\n",
    "print correct_middle_counts\n",
    "print total_utility\n",
    "print total_status\n",
    "print total_middle\n",
    "\n",
    "a = 1.0 * correct_status_counts/total_status\n",
    "print a\n",
    "b = 1.0 * (total_status-correct_status_counts)/total_status\n",
    "print b\n",
    "print a+b\n",
    "\n",
    "c = 1.0 * correct_utility_counts/total_utility\n",
    "d = 1.0 * (total_utility-correct_utility_counts)/total_utility\n",
    "print c\n",
    "print d\n",
    "print c+d\n",
    "\n",
    "print 1.0*(correct_utility_counts + correct_status_counts)/(total_status+total_utility)\n",
    "\n",
    "#n, bins, patches = plt.hist(x, 50, facecolor='g', alpha=0.7)\n",
    "\n",
    "#plt.xlabel('Labels')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title('Histogram of IQ')\n",
    "#plt.grid(True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
